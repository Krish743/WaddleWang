# PolicyAssist RAG Backend â€“ copy to .env and fill in

# Required: LLM API key (OpenAI, Groq, or any OpenAI-compatible API)
API_KEY=sk-your-key-here
# For Groq: API_KEY=gsk-your-groq-key-here

# Optional: use a different base URL (e.g. Groq, Azure, local model)
# For Groq: BASE_URL=https://api.groq.com/openai/v1
# BASE_URL=https://your-api.com/v1

# Optional: model names
# For OpenAI: LLM_MODEL=gpt-4o-mini
# For Groq: LLM_MODEL=llama-3.1-70b-versatile
# Or: LLM_MODEL=mixtral-8x7b-32768

# Embeddings configuration
# Use Hugging Face (recommended - free, local, no API key needed)
EMBEDDING_PROVIDER=huggingface
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# Popular Hugging Face models:
# - sentence-transformers/all-MiniLM-L6-v2 (fast, 384 dim)
# - sentence-transformers/all-mpnet-base-v2 (better quality, 768 dim)
# - sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 (multilingual)

# Or use OpenAI embeddings (requires API key)
# EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL=text-embedding-3-small
# EMBEDDING_API_KEY=sk-your-openai-key-for-embeddings
# EMBEDDING_BASE_URL=https://api.openai.com/v1

# Optional: chunk size for document splitting
# CHUNK_SIZE=1000
# CHUNK_OVERLAP=200
