# PolicyAssist RAG Backend – Environment Variables
# Copy this file to .env and fill in your API keys

# ============================================================================
# LLM Configuration (Required)
# ============================================================================
# Choose one: Groq (recommended for speed) or OpenAI

# For Groq (fast, free tier available):
# Note: We use Llama models (Meta) but access them via OpenAI-compatible API format
# The /openai/v1 path is Groq's OpenAI-compatible endpoint (not OpenAI's servers!)
# The model (llama-3.1-70b-versatile) is Llama, but the API format is OpenAI-compatible
API_KEY=gsk-your-groq-key-here
BASE_URL=https://api.groq.com/openai/v1
LLM_MODEL=llama-3.1-70b-versatile
# Popular Groq models:
# - llama-3.1-70b-versatile (recommended)
# - mixtral-8x7b-32768
# - llama-3.1-8b-instant (faster, smaller)

# For OpenAI:
# API_KEY=sk-your-openai-key-here
# LLM_MODEL=gpt-4o-mini

# ============================================================================
# Embeddings Configuration
# ============================================================================
# Hugging Face (recommended - free, local, no API key needed)
EMBEDDING_PROVIDER=huggingface
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Popular Hugging Face models:
# - sentence-transformers/all-MiniLM-L6-v2 (fast, 384 dim) ← default
# - sentence-transformers/all-mpnet-base-v2 (better quality, 768 dim)
# - sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 (multilingual)

# Alternative: OpenAI embeddings (requires API key)
# EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL=text-embedding-3-small
# EMBEDDING_API_KEY=sk-your-openai-key-for-embeddings
# EMBEDDING_BASE_URL=https://api.openai.com/v1

# ============================================================================
# Optional: Document Processing
# ============================================================================
# CHUNK_SIZE=1000
# CHUNK_OVERLAP=200
